{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0331,  0.1150, -0.0534, -0.1486,  0.0619]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 定义优化器\n",
    "import torch\n",
    "import random\n",
    "from RobotEnv import RobotEnv\n",
    "from utils import *\n",
    "\n",
    "env = RobotEnv(screen_width=400, screen_height=400)\n",
    "# size of obs\n",
    "observation_length = env.observation_space.shape[0]\n",
    "action_length = env.action_space.n\n",
    "\n",
    "state_size = 8\n",
    "hidden_size = 128\n",
    "# note 加载GRU模型\n",
    "# gru.load_state_dict(torch.load('gru.pth'))\n",
    "\n",
    "# 新网络，将GRU的输出和state堆叠后作为mlp的输入\n",
    "class DQN_SP(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN_SP, self).__init__()\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(observation_length * 2, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, action_length),\n",
    "        )\n",
    "        self.gru = GRUModel(state_size, hidden_size, state_size)\n",
    "\n",
    "    def forward(self, s):\n",
    "        input = torch.cat([s, self.gru(s.reshape(-1, 1, 8))], dim=1)\n",
    "        q_vector = self.mlp(input)\n",
    "        return q_vector\n",
    "\n",
    "\n",
    "model = DQN_SP()\n",
    "\n",
    "model_delay = DQN_SP()\n",
    "model_delay.mlp.load_state_dict(model.mlp.state_dict())\n",
    "model_delay.gru.load_state_dict(model.gru.state_dict())\n",
    "# 冻结gru参数\n",
    "for param in model.gru.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model_delay.gru.parameters():\n",
    "    param.requires_grad = False\n",
    "# 测试\n",
    "s = torch.randn(1, 8)\n",
    "print(model(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:101102,test_result:-71.47250000000001\n",
      "step:202133,test_result:-84.66\n",
      "step:303837,test_result:-133.305\n",
      "step:404828,test_result:-82.555\n",
      "step:506183,test_result:-82.94000000000001\n",
      "step:607226,test_result:-37.00749999999999\n",
      "step:708402,test_result:-36.5775\n",
      "step:809988,test_result:-129.73\n",
      "step:911578,test_result:-108.82250000000003\n",
      "step:1012836,test_result:-78.92\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\2024Spring\\毕业设计\\code\\RL\\DQN_SP.ipynb 单元格 5\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/DQN_SP.ipynb#X20sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m             writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m\"\u001b[39m\u001b[39mLoss\u001b[39m\u001b[39m\"\u001b[39m, loss\u001b[39m.\u001b[39mitem(), global_step\u001b[39m=\u001b[39mn_step)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/DQN_SP.ipynb#X20sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     writer\u001b[39m.\u001b[39mclose()  \u001b[39m# 训练结束后关闭writer\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/DQN_SP.ipynb#X20sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m train()\n",
      "\u001b[1;32me:\\2024Spring\\毕业设计\\code\\RL\\DQN_SP.ipynb 单元格 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/DQN_SP.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m writer \u001b[39m=\u001b[39m SummaryWriter(\u001b[39m\"\u001b[39m\u001b[39m./logs/DQN_SP\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/DQN_SP.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mwhile\u001b[39;00m n_step \u001b[39m<\u001b[39m \u001b[39m50_000_000\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/DQN_SP.ipynb#X20sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     n_step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49mupdate()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/DQN_SP.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# 每次更新数据后,训练N次\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/DQN_SP.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m200\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/DQN_SP.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         \u001b[39m# 采样N条数据\u001b[39;00m\n",
      "File \u001b[1;32me:\\2024Spring\\毕业设计\\code\\RL\\utils.py:25\u001b[0m, in \u001b[0;36mPool.update\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     23\u001b[0m len_new_data \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool) \u001b[39m-\u001b[39m old_len \u001b[39m<\u001b[39m \u001b[39m10_000\u001b[39m:\n\u001b[1;32m---> 25\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontroller\u001b[39m.\u001b[39;49mplay()[\u001b[39m0\u001b[39m]\n\u001b[0;32m     26\u001b[0m     len_new_data \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(new_data)\n\u001b[0;32m     27\u001b[0m     \u001b[39m# print(len_new_data)\u001b[39;00m\n",
      "File \u001b[1;32me:\\2024Spring\\毕业设计\\code\\RL\\utils.py:63\u001b[0m, in \u001b[0;36mController.play\u001b[1;34m(self, mode, show)\u001b[0m\n\u001b[0;32m     61\u001b[0m truncated \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m terminated:\n\u001b[1;32m---> 63\u001b[0m     a \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(torch\u001b[39m.\u001b[39;49mFloatTensor(s)\u001b[39m.\u001b[39;49mreshape(\n\u001b[0;32m     64\u001b[0m         \u001b[39m1\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobservation_length))\u001b[39m.\u001b[39margmax()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m random\u001b[39m.\u001b[39mrandom() \u001b[39m<\u001b[39m \u001b[39m0.1\u001b[39m:\n\u001b[0;32m     66\u001b[0m         a \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39msample()\n",
      "File \u001b[1;32me:\\Miniconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32me:\\Miniconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32me:\\2024Spring\\毕业设计\\code\\RL\\DQN_SP.ipynb 单元格 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/DQN_SP.ipynb#X20sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, s):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/DQN_SP.ipynb#X20sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([s, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgru(s\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m8\u001b[39;49m))], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/DQN_SP.ipynb#X20sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     q_vector \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp(\u001b[39minput\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/DQN_SP.ipynb#X20sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m q_vector\n",
      "File \u001b[1;32me:\\Miniconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32me:\\Miniconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\2024Spring\\毕业设计\\code\\RL\\utils.py:88\u001b[0m, in \u001b[0;36mGRUModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 88\u001b[0m     out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgru(x)\n\u001b[0;32m     89\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(out[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :])\n\u001b[0;32m     90\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32me:\\Miniconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32me:\\Miniconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\Miniconda3\\envs\\RL\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1100\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mgru(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m   1101\u001b[0m                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m   1102\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1103\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mgru(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m   1104\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# 复制参数\n",
    "controller = Controller(model, env)\n",
    "pool = Pool(controller)\n",
    "# 训练\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    # 共训练n_step次\n",
    "    n_step = 0\n",
    "    log_interval = 100_000\n",
    "    last_log_step = 0\n",
    "    writer = SummaryWriter(\"./logs/DQN_SP\")\n",
    "    while n_step < 50_000_000:\n",
    "        n_step += pool.update()\n",
    "        # 每次更新数据后,训练N次\n",
    "        for i in range(200):\n",
    "            # 采样N条数据\n",
    "            state, action, reward, next_state, terminated = pool.sample()\n",
    "            # 计算value\n",
    "            value = model(state).gather(dim=1, index=action)\n",
    "            # 计算target\n",
    "            with torch.no_grad():\n",
    "                # 使用原模型计算动作,使用延迟模型计算target,进一步缓解自举\n",
    "                next_action = model(next_state).argmax(dim=1, keepdim=True)\n",
    "                target = model_delay(next_state).gather(dim=1, index=next_action)\n",
    "            target = target * 0.99 * (1 - terminated) + reward\n",
    "            loss = loss_fn(value, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # 复制参数\n",
    "        if (n_step - last_log_step) >= log_interval:\n",
    "            model_delay.load_state_dict(model.state_dict())\n",
    "            test_result = (\n",
    "                sum([pool.controller.play(mode=\"test\")[-1] for _ in range(20)]) / 20\n",
    "            )\n",
    "            print(f\"step:{n_step},test_result:{test_result}\")\n",
    "            last_log_step = n_step\n",
    "            # 将步数，测试结果和损失写入TensorBoard\n",
    "            writer.add_scalar(\"Step\", n_step, global_step=n_step)\n",
    "            writer.add_scalar(\"Test Result\", test_result, global_step=n_step)\n",
    "            writer.add_scalar(\"Loss\", loss.item(), global_step=n_step)\n",
    "    writer.close()  # 训练结束后关闭writer\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型参数\n",
    "torch.save(model.state_dict(), \"DQN.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model.load_state_dict(torch.load(\"DQN.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = RobotEnv(screen_width=400, screen_height=400)\n",
    "controller = Controller(model, env)\n",
    "controller.play(mode=\"test\", show=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

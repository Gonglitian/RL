{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RobotEnv import RobotEnv\n",
    "import random\n",
    "env = RobotEnv(screen_width=400, screen_height=400)\n",
    "# size of obs\n",
    "observation_length = env.observation_space.shape[0]\n",
    "action_length = env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class SelectOutput(torch.nn.Module):\n",
    "    def forward(self, inputs):\n",
    "        outputs, (hidden, cell) = inputs\n",
    "        return outputs\n",
    "\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(observation_length, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.LSTM(64, 64, batch_first=True),\n",
    "    SelectOutput(),  # 添加自定义层\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, action_length),\n",
    ")\n",
    "model_delay = torch.nn.Sequential(\n",
    "    torch.nn.Linear(observation_length, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.LSTM(64, 64, batch_first=True),\n",
    "    SelectOutput(),  # 添加自定义层\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, action_length),\n",
    ")\n",
    "# 复制参数\n",
    "model_delay.load_state_dict(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单局游戏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器\n",
    "from utils import Controller,Pool\n",
    "controller = Controller(model, env)\n",
    "pool = Pool(controller)\n",
    "pool.update()\n",
    "pool.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:101286,test_result:-96.73750000000003\n",
      "step:202098,test_result:-68.7875\n",
      "step:303756,test_result:-49.02250000000001\n",
      "step:405020,test_result:-31.8825\n",
      "step:506121,test_result:-55.57250000000001\n",
      "step:607524,test_result:-44.410000000000004\n",
      "step:708584,test_result:-40.81250000000001\n",
      "step:809928,test_result:-82.68750000000006\n",
      "step:911629,test_result:-47.40999999999998\n",
      "step:1013063,test_result:-59.6475\n",
      "step:1114264,test_result:-64.21750000000004\n",
      "step:1215964,test_result:-63.76500000000001\n",
      "step:1317366,test_result:-146.25000000000003\n",
      "step:1418985,test_result:-136.82999999999998\n",
      "step:1520087,test_result:-83.77000000000001\n",
      "step:1621289,test_result:-44.41500000000001\n",
      "step:1722760,test_result:-28.615\n",
      "step:1824132,test_result:-133.2425\n",
      "step:1925113,test_result:-136.45000000000002\n",
      "step:2025915,test_result:-53.902499999999996\n",
      "step:2127532,test_result:-66.61250000000001\n",
      "step:2228982,test_result:-36.13000000000001\n",
      "step:2330683,test_result:-57.09500000000001\n",
      "step:2431784,test_result:-36.85750000000001\n",
      "step:2532800,test_result:-68.48\n",
      "step:2633902,test_result:-77.915\n",
      "step:2735153,test_result:-48.125000000000014\n",
      "step:2836264,test_result:-68.8\n",
      "step:2937868,test_result:-18.592500000000012\n",
      "step:3038909,test_result:-120.19749999999999\n",
      "step:3140011,test_result:-119.93250000000003\n",
      "step:3241287,test_result:-98.37499999999997\n",
      "step:3342089,test_result:-65.01\n",
      "step:3443009,test_result:-51.9375\n",
      "step:3544109,test_result:-99.89500000000001\n",
      "step:3645209,test_result:-67.15250000000002\n",
      "step:3746613,test_result:-93.70500000000001\n",
      "step:3847869,test_result:-82.92000000000002\n",
      "step:3949471,test_result:-103.87000000000003\n",
      "step:4050572,test_result:-91.53999999999999\n",
      "step:4151847,test_result:-98.77000000000001\n",
      "step:4252601,test_result:-62.16250000000002\n",
      "step:4353614,test_result:-45.312500000000014\n",
      "step:4454851,test_result:-70.62499999999999\n",
      "step:4555748,test_result:-79.015\n",
      "step:4657124,test_result:-54.995000000000026\n",
      "step:4758674,test_result:-139.94\n",
      "step:4860075,test_result:-65.1025\n",
      "step:4961178,test_result:-54.41750000000002\n",
      "step:5062880,test_result:-68.75250000000001\n",
      "step:5164129,test_result:-88.64250000000001\n",
      "step:5265229,test_result:-23.985\n",
      "step:5366528,test_result:-52.44000000000001\n",
      "step:5467629,test_result:-71.05500000000002\n",
      "step:5568573,test_result:-123.0125\n",
      "step:5669973,test_result:-93.77500000000003\n",
      "step:5771074,test_result:-76.305\n",
      "step:5872049,test_result:-81.91250000000002\n",
      "step:5973581,test_result:-146.125\n",
      "step:6074927,test_result:-52.675\n",
      "step:6176117,test_result:-103.51250000000005\n",
      "step:6277455,test_result:-70.16499999999999\n",
      "step:6378557,test_result:-94.22500000000001\n",
      "step:6480088,test_result:-100.95000000000002\n",
      "step:6581489,test_result:-49.15500000000001\n",
      "step:6682163,test_result:-67.895\n",
      "step:6783735,test_result:-54.69750000000001\n",
      "step:6884613,test_result:-83.94750000000002\n",
      "step:6985413,test_result:-68.25000000000001\n",
      "step:7087048,test_result:-28.135\n",
      "step:7188556,test_result:-82.0175\n",
      "step:7289956,test_result:-54.3525\n",
      "step:7391031,test_result:-101.395\n",
      "step:7492432,test_result:-54.935\n",
      "step:7593336,test_result:-83.7925\n",
      "step:7694573,test_result:-55.92750000000001\n",
      "step:7795374,test_result:-77.32000000000002\n",
      "step:7896775,test_result:-60.014999999999986\n",
      "step:7998342,test_result:-81.1625\n",
      "step:8099691,test_result:-33.095000000000006\n",
      "step:8201205,test_result:-63.11\n",
      "step:8302306,test_result:-61.447500000000005\n",
      "step:8403668,test_result:-70.85250000000002\n",
      "step:8505182,test_result:-43.195\n",
      "step:8606886,test_result:-40.1075\n",
      "step:8707989,test_result:-92.2125\n",
      "step:8809692,test_result:-83.18750000000001\n",
      "step:8911093,test_result:-86.7825\n",
      "step:9012566,test_result:-79.25750000000001\n",
      "step:9113668,test_result:-61.945000000000036\n",
      "step:9215177,test_result:-57.947500000000005\n",
      "step:9316564,test_result:-65.07500000000002\n",
      "step:9418165,test_result:-46.462499999999984\n",
      "step:9518898,test_result:-53.83750000000001\n",
      "step:9620300,test_result:-112.19500000000002\n",
      "step:9722000,test_result:-94.88500000000002\n",
      "step:9823196,test_result:-124.04250000000002\n",
      "step:9924897,test_result:-94.6375\n",
      "step:10025897,test_result:-84.48750000000005\n",
      "step:10127136,test_result:-150.85\n",
      "step:10228639,test_result:-52.605000000000004\n",
      "step:10329844,test_result:-132.0125\n",
      "step:10431245,test_result:-97.93\n",
      "step:10532646,test_result:-26.5375\n",
      "step:10634274,test_result:-89.39500000000001\n",
      "step:10735375,test_result:-102.0\n",
      "step:10836476,test_result:-82.21000000000001\n",
      "step:10937877,test_result:-140.1\n",
      "step:11039578,test_result:-67.99250000000002\n",
      "step:11140681,test_result:-71.15500000000002\n",
      "step:11241776,test_result:-118.51750000000001\n",
      "step:11342428,test_result:-66.0525\n",
      "step:11443794,test_result:-33.245000000000005\n",
      "step:11545365,test_result:-112.43000000000002\n",
      "step:11646600,test_result:-37.910000000000004\n",
      "step:11747931,test_result:-99.23750000000004\n",
      "step:11848992,test_result:-44.175000000000004\n",
      "step:11950018,test_result:-58.0625\n",
      "step:12051058,test_result:-44.137499999999996\n",
      "step:12152146,test_result:-128.375\n",
      "step:12253847,test_result:-68.61000000000001\n",
      "step:12355104,test_result:-76.99750000000002\n",
      "step:12455875,test_result:-29.965000000000014\n",
      "step:12556514,test_result:-21.717500000000005\n",
      "step:12657801,test_result:-8.290000000000003\n",
      "step:12758745,test_result:-138.0\n",
      "step:12859547,test_result:-122.25000000000004\n",
      "step:12960950,test_result:-61.11999999999999\n",
      "step:13061834,test_result:-103.86500000000001\n",
      "step:13163235,test_result:-84.06000000000003\n",
      "step:13263964,test_result:-60.88250000000003\n",
      "step:13365065,test_result:-33.930000000000014\n",
      "step:13466340,test_result:-135.60750000000002\n",
      "step:13567742,test_result:-38.42\n",
      "step:13669061,test_result:-38.385\n",
      "step:13770162,test_result:-30.225000000000012\n",
      "step:13871381,test_result:-79.79500000000002\n",
      "step:13972818,test_result:-99.5875\n",
      "step:14073918,test_result:-52.50500000000002\n",
      "step:14175247,test_result:-61.9125\n",
      "step:14276348,test_result:-122.12500000000003\n",
      "step:14377449,test_result:-59.250000000000014\n",
      "step:14478827,test_result:-40.602500000000006\n",
      "step:14580551,test_result:-90.66250000000002\n",
      "step:14681641,test_result:-87.70499999999996\n",
      "step:14783125,test_result:-85.77250000000001\n",
      "step:14884327,test_result:-34.042500000000004\n",
      "step:14985605,test_result:-101.53500000000001\n",
      "step:15086705,test_result:-90.7\n",
      "step:15188048,test_result:-110.05000000000003\n",
      "step:15289449,test_result:-78.40750000000003\n",
      "step:15391116,test_result:-53.025\n",
      "step:15492682,test_result:-27.287500000000033\n",
      "step:15594382,test_result:-27.26000000000002\n",
      "step:15695484,test_result:-101.21000000000005\n",
      "step:15796871,test_result:-94.17500000000001\n",
      "step:15897673,test_result:-133.265\n",
      "step:15998764,test_result:-110.91750000000002\n",
      "step:16100449,test_result:-74.44250000000002\n",
      "step:16201877,test_result:-70.18500000000003\n",
      "step:16302677,test_result:-125.44000000000003\n",
      "step:16404377,test_result:-42.552500000000016\n",
      "step:16505777,test_result:-60.75500000000005\n",
      "step:16606877,test_result:-35.502500000000026\n",
      "step:16707793,test_result:-48.535000000000004\n",
      "step:16809653,test_result:-54.10000000000002\n",
      "step:16911053,test_result:-97.19750000000002\n",
      "step:17012119,test_result:-71.72749999999999\n",
      "step:17112920,test_result:-94.81250000000001\n",
      "step:17214620,test_result:-84.8075\n",
      "step:17315721,test_result:-123.9325\n",
      "step:17416522,test_result:-97.62\n",
      "step:17517923,test_result:-64.87000000000002\n",
      "step:17619024,test_result:-97.33500000000001\n",
      "step:17720367,test_result:-85.69000000000003\n",
      "step:17821725,test_result:-37.720000000000006\n",
      "step:17923191,test_result:-61.454999999999984\n",
      "step:18024593,test_result:-74.56999999999998\n",
      "step:18126293,test_result:-75.77000000000001\n",
      "step:18228281,test_result:-68.6375\n",
      "step:18329382,test_result:-97.31000000000002\n",
      "step:18430659,test_result:-78.03250000000003\n",
      "step:18532283,test_result:-54.81500000000001\n",
      "step:18633569,test_result:-53.437500000000036\n",
      "step:18734607,test_result:-53.63500000000003\n",
      "step:18835708,test_result:-104.45000000000002\n",
      "step:18936808,test_result:-80.19749999999999\n",
      "step:19037668,test_result:-30.46500000000001\n",
      "step:19139196,test_result:-79.88499999999999\n",
      "step:19240793,test_result:-65.44250000000001\n",
      "step:19342195,test_result:-147.51000000000002\n",
      "step:19444093,test_result:-93.60499999999999\n",
      "step:19545793,test_result:-86.5925\n",
      "step:19647194,test_result:-70.75\n",
      "step:19748895,test_result:-62.982500000000016\n",
      "step:19850241,test_result:-71.38000000000001\n",
      "step:19951929,test_result:-74.90750000000004\n",
      "step:20053477,test_result:-46.92249999999999\n",
      "step:20154569,test_result:-76.395\n",
      "step:20256270,test_result:-85.405\n",
      "step:20357278,test_result:-66.89500000000004\n",
      "step:20458621,test_result:-69.845\n",
      "step:20559945,test_result:-81.61000000000004\n",
      "step:20661645,test_result:-75.55499999999998\n",
      "step:20763346,test_result:-87.85249999999999\n",
      "step:20864531,test_result:-110.2\n",
      "step:20966135,test_result:-134.1975\n",
      "step:21067536,test_result:-143.40500000000003\n",
      "step:21169238,test_result:-32.464999999999996\n",
      "step:21270972,test_result:-37.857500000000016\n",
      "step:21372373,test_result:-47.84250000000001\n",
      "step:21473335,test_result:-71.15249999999997\n",
      "step:21574576,test_result:-72.24500000000002\n",
      "step:21676254,test_result:-93.25250000000001\n",
      "step:21777957,test_result:-67.77\n",
      "step:21879658,test_result:-56.84750000000001\n",
      "step:21981042,test_result:-95.16749999999999\n",
      "step:22082365,test_result:-63.482500000000016\n",
      "step:22183469,test_result:-120.72500000000002\n",
      "step:22284871,test_result:-110.85\n",
      "step:22386271,test_result:-54.280000000000015\n",
      "step:22487768,test_result:-83.885\n",
      "step:22589168,test_result:-41.81750000000001\n",
      "step:22690793,test_result:-103.74000000000001\n",
      "step:22791894,test_result:-52.557500000000026\n",
      "step:22893507,test_result:-69.87750000000001\n",
      "step:22994718,test_result:-95.76000000000002\n",
      "step:23096119,test_result:-117.07000000000002\n",
      "step:23197520,test_result:-71.96750000000002\n",
      "step:23298811,test_result:-78.75250000000003\n",
      "step:23400029,test_result:-30.079999999999995\n",
      "step:23501311,test_result:-49.61000000000002\n",
      "step:23602569,test_result:-53.65250000000001\n",
      "step:23703468,test_result:-20.727499999999985\n",
      "step:23804526,test_result:-41.88000000000002\n",
      "step:23906227,test_result:-166.0625\n",
      "step:24007905,test_result:-69.69500000000001\n",
      "step:24109005,test_result:-106.61500000000001\n",
      "step:24210406,test_result:-91.26\n",
      "step:24311806,test_result:-129.3675\n",
      "step:24412907,test_result:-93.76250000000003\n",
      "step:24514007,test_result:-61.15250000000001\n",
      "step:24615407,test_result:-61.5375\n",
      "step:24716923,test_result:-54.9775\n",
      "step:24818236,test_result:-76.68000000000002\n",
      "step:24919636,test_result:-83.38000000000002\n",
      "step:25020410,test_result:-65.38250000000001\n",
      "step:25121811,test_result:-30.25000000000001\n",
      "step:25222642,test_result:-68.23000000000003\n",
      "step:25323896,test_result:-63.59000000000001\n",
      "step:25425209,test_result:-92.08249999999998\n",
      "step:25526687,test_result:-54.93500000000004\n",
      "step:25628234,test_result:-65.6875\n",
      "step:25729592,test_result:-82.31250000000003\n",
      "step:25830731,test_result:-44.964999999999996\n",
      "step:25932131,test_result:-89.25250000000003\n",
      "step:26033389,test_result:-64.67749999999998\n",
      "step:26134866,test_result:-79.12250000000002\n",
      "step:26235967,test_result:-100.92250000000004\n",
      "step:26337068,test_result:-92.63000000000002\n",
      "step:26438102,test_result:-77.03500000000001\n",
      "step:26539531,test_result:-84.80999999999999\n",
      "step:26640933,test_result:-77.51000000000002\n",
      "step:26742033,test_result:-64.54999999999998\n",
      "step:26844121,test_result:-64.62500000000003\n",
      "step:26945620,test_result:-35.370000000000005\n",
      "step:27046720,test_result:-63.02750000000002\n",
      "step:27148120,test_result:-76.79750000000001\n",
      "step:27249624,test_result:-69.11000000000001\n",
      "step:27350898,test_result:-98.16499999999999\n",
      "step:27452504,test_result:-131.9375\n",
      "step:27554204,test_result:-40.37250000000003\n",
      "step:27655358,test_result:-88.19749999999999\n",
      "step:27756591,test_result:-47.489999999999995\n",
      "step:27858471,test_result:-32.55000000000001\n",
      "step:27960213,test_result:-60.575000000000024\n",
      "step:28061315,test_result:-71.95000000000002\n",
      "step:28162717,test_result:-115.905\n",
      "step:28264036,test_result:-102.78250000000003\n",
      "step:28364808,test_result:-66.465\n",
      "step:28465908,test_result:-48.47000000000001\n",
      "step:28566976,test_result:-90.14500000000002\n",
      "step:28668677,test_result:-114.79750000000001\n",
      "step:28770077,test_result:-32.23\n",
      "step:28871723,test_result:-80.47250000000001\n",
      "step:28973300,test_result:-57.59250000000001\n",
      "step:29074886,test_result:-103.14500000000002\n",
      "step:29176589,test_result:-61.592500000000015\n",
      "step:29278149,test_result:-30.43750000000001\n",
      "step:29379714,test_result:-76.9\n",
      "step:29481414,test_result:-111.35749999999999\n",
      "step:29582514,test_result:-127.1075\n",
      "step:29684096,test_result:-63.030000000000015\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# 训练\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    # 共训练n_step次\n",
    "    n_step = 0\n",
    "    log_interval = 100_000\n",
    "    last_log_step = 0\n",
    "    writer = SummaryWriter(\"./logs/DRQN_logs\")\n",
    "    while n_step < 50_000_000:\n",
    "        n_step += pool.update()\n",
    "        # print(f\"n_step:{n_step}\")\n",
    "        # 每次更新数据后,训练N次\n",
    "        for i in range(200):\n",
    "            # print(f\"i:{i}\")\n",
    "            # 采样N条数据\n",
    "            state, action, reward, next_state, terminated = pool.sample()\n",
    "\n",
    "            # 计算value\n",
    "            value = model(state).gather(dim=1, index=action)\n",
    "\n",
    "            # 计算target\n",
    "            with torch.no_grad():\n",
    "                # 使用原模型计算动作,使用延迟模型计算target,进一步缓解自举\n",
    "                next_action = model(next_state).argmax(dim=1, keepdim=True)\n",
    "                target = model_delay(next_state).gather(dim=1,\n",
    "                                                        index=next_action)\n",
    "            target = target * 0.99 * (1 - terminated) + reward\n",
    "\n",
    "            loss = loss_fn(value, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # 复制参数\n",
    "        if (n_step - last_log_step) >=log_interval:\n",
    "            model_delay.load_state_dict(model.state_dict())\n",
    "            test_result = sum([pool.controller.play(mode=\"test\")[-1] for _ in range(20)]) / 20\n",
    "            print(f\"step:{n_step},test_result:{test_result}\")\n",
    "            last_log_step = n_step\n",
    "            # 将步数，测试结果和损失写入TensorBoard\n",
    "            writer.add_scalar('Step', n_step, global_step=n_step)\n",
    "            writer.add_scalar('Test Result', test_result, global_step=n_step)\n",
    "            writer.add_scalar('Loss', loss.item(), global_step=n_step)      \n",
    "    writer.close()  # 训练结束后关闭writer\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型参数\n",
    "torch.save(model.state_dict(), 'DRQN.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from RobotEnv import RobotEnv\n",
    "import numpy as np\n",
    "t_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(8, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 4),\n",
    ")\n",
    "env = RobotEnv(400,400)\n",
    "# 玩一局游戏获取轨迹\n",
    "controller = Controller(t_model,env)\n",
    "t_list = []\n",
    "s, _ = env.reset()\n",
    "\n",
    "\n",
    "def get_trajectory(model,env):\n",
    "    t = []\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    while not (terminated or truncated):\n",
    "        a = model(torch.FloatTensor(s).reshape(\n",
    "            1, 8)).argmax().item()\n",
    "        if random.random() < 0.1:\n",
    "            a = env.action_space.sample()\n",
    "        ns, r, terminated, truncated, _ = env.step(a)\n",
    "        t.append(ns)\n",
    "    env.reset()\n",
    "    return np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取多条轨迹，存储至t_list\n",
    "for i in range(10_0):\n",
    "    t = get_trajectory(t_model,env)\n",
    "    t_list.append(t)\n",
    "len(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 假设每个状态的大小为8\n",
    "state_size = 8\n",
    "hidden_size = 128\n",
    "\n",
    "# 创建模型、优化器和损失函数\n",
    "model = GRUModel(state_size, hidden_size, state_size)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = MSELoss()\n",
    "\n",
    "#测试GRU输出\n",
    "x = torch.randn(1, 1, state_size)\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Trajectory 1, Loss: 5098.044453160044\n",
      "Epoch 1, Trajectory 2, Loss: 15367.271354166667\n",
      "Test Epoch 1, Loss: 7005.301243520734\n",
      "Epoch 2, Trajectory 1, Loss: 402.14101045530947\n",
      "Epoch 2, Trajectory 2, Loss: 12688.630911458333\n",
      "Test Epoch 2, Loss: 5577.662612141149\n",
      "Epoch 3, Trajectory 1, Loss: 335.02016754880475\n",
      "Epoch 3, Trajectory 2, Loss: 12817.427584635416\n",
      "Test Epoch 3, Loss: 5595.822585227273\n",
      "Epoch 4, Trajectory 1, Loss: 297.4739058138651\n",
      "Epoch 4, Trajectory 2, Loss: 12480.147356770833\n",
      "Test Epoch 4, Loss: 5536.82112490032\n",
      "Epoch 5, Trajectory 1, Loss: 275.2838507932909\n",
      "Epoch 5, Trajectory 2, Loss: 11955.056796875\n",
      "Test Epoch 5, Loss: 5364.43776166268\n",
      "Epoch 6, Trajectory 1, Loss: 272.57717103832647\n",
      "Epoch 6, Trajectory 2, Loss: 11335.899186197918\n",
      "Test Epoch 6, Loss: 5099.79710052831\n",
      "Epoch 7, Trajectory 1, Loss: 259.1794842959591\n",
      "Epoch 7, Trajectory 2, Loss: 10340.150032552083\n",
      "Test Epoch 7, Loss: 4643.468452202951\n",
      "Epoch 8, Trajectory 1, Loss: 234.5595650982058\n",
      "Epoch 8, Trajectory 2, Loss: 10565.149381510417\n",
      "Test Epoch 8, Loss: 4732.1105300538275\n",
      "Epoch 9, Trajectory 1, Loss: 218.3243500075272\n",
      "Epoch 9, Trajectory 2, Loss: 9630.19357421875\n",
      "Test Epoch 9, Loss: 4376.268971790271\n",
      "Epoch 10, Trajectory 1, Loss: 196.38699670625076\n",
      "Epoch 10, Trajectory 2, Loss: 9273.319694010417\n",
      "Test Epoch 10, Loss: 4221.679065739633\n",
      "Epoch 11, Trajectory 1, Loss: 194.0029132717534\n",
      "Epoch 11, Trajectory 2, Loss: 8186.075735677084\n",
      "Test Epoch 11, Loss: 3725.942244816587\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\2024Spring\\毕业设计\\code\\RL\\state_predict.ipynb 单元格 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/state_predict.ipynb#W4sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m         writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m'\u001b[39m\u001b[39mLoss\u001b[39m\u001b[39m'\u001b[39m, epoch_loss, global_step\u001b[39m=\u001b[39mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/state_predict.ipynb#W4sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTest Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{\u001b[39;00mepoch_loss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/state_predict.ipynb#W4sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m train()\n",
      "\u001b[1;32me:\\2024Spring\\毕业设计\\code\\RL\\state_predict.ipynb 单元格 4\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/state_predict.ipynb#W4sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# 反向传播和优化\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/state_predict.ipynb#W4sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/state_predict.ipynb#W4sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/state_predict.ipynb#W4sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m t_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/2024Spring/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1/code/RL/state_predict.ipynb#W4sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32me:\\Miniconda3\\envs\\RL\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    523\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    524\u001b[0m )\n",
      "File \u001b[1;32me:\\Miniconda3\\envs\\RL\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m     tensors,\n\u001b[0;32m    268\u001b[0m     grad_tensors_,\n\u001b[0;32m    269\u001b[0m     retain_graph,\n\u001b[0;32m    270\u001b[0m     create_graph,\n\u001b[0;32m    271\u001b[0m     inputs,\n\u001b[0;32m    272\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    273\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    274\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 训练模型\n",
    "writer = SummaryWriter(\"./logs/state_prediction\")\n",
    "\n",
    "\n",
    "def test():\n",
    "    loss_sum = 0\n",
    "    for trajectory in t_list:\n",
    "        trajectory = torch.tensor(trajectory, dtype=torch.float32)\n",
    "        m = len(trajectory)\n",
    "        t_loss = 0\n",
    "        for j, state in enumerate(trajectory):\n",
    "            if j == m - 1:\n",
    "                break\n",
    "            s = torch.FloatTensor(state).reshape(1, 1, 8)\n",
    "            next_s = torch.FloatTensor(trajectory[j + 1]).reshape(1, 8)\n",
    "            predict_state = model(s)\n",
    "            t_loss+= loss_fn(predict_state, next_s)\n",
    "        avg_loss_t = t_loss.item() / m\n",
    "        loss_sum += avg_loss_t\n",
    "    return loss_sum / len(t_list)\n",
    "\n",
    "def train():\n",
    "    for epoch in range(30):  # 进行100个训练周期\n",
    "        for i,trajectory in enumerate(t_list):\n",
    "            # 将轨迹转换为Tensor\n",
    "            trajectory = torch.tensor(trajectory, dtype=torch.float32)\n",
    "            # 获取输入和目标\n",
    "            m = len(trajectory)\n",
    "            t_loss = 0\n",
    "            repeat = 10\n",
    "            for n in range(repeat):\n",
    "                for j,state in enumerate(trajectory):\n",
    "                    if j == m - 1:\n",
    "                        break\n",
    "                    s = torch.FloatTensor(state).reshape(1, 1, 8)\n",
    "                    next_s = torch.FloatTensor(trajectory[j + 1]).reshape(1, 8)\n",
    "                    predict_state = model(s)\n",
    "                    # 计算损失\n",
    "                    loss = loss_fn(predict_state, next_s)\n",
    "                    # 反向传播和优化\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    t_loss += loss.item()\n",
    "                    optimizer.step()\n",
    "            avg_loss = t_loss / (m * repeat)\n",
    "            print(f'Epoch {epoch+1}, Trajectory {i+1}, Loss: {avg_loss}')\n",
    "        # 每个epoch测试一次，记录所有轨迹预测的平均loss\n",
    "        epoch_loss = test()\n",
    "        writer.add_scalar('Loss', epoch_loss, global_step=epoch+1)\n",
    "        print(f'Test Epoch {epoch+1}, Loss: {epoch_loss}')\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save \n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
